{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Glove_Spam_Classification.ipynb의 사본","version":"0.3.2","provenance":[{"file_id":"1O-L0pG2UoMs7Kp_aa0nSLkauAYlp50oo","timestamp":1564724532671}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"y5L8JGY_vWDQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":504},"outputId":"6ec40d28-66dd-4ede-ec29-68181f3f51a7","executionInfo":{"status":"ok","timestamp":1564724642477,"user_tz":-540,"elapsed":70038,"user":{"displayName":"군고구마","photoUrl":"https://lh5.googleusercontent.com/-I0XUuvaS1h0/AAAAAAAAAAI/AAAAAAAAAC4/1a-GQoFjqY4/s64/photo.jpg","userId":"10196243389166907276"}}},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip glove.6B.zip"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2019-08-02 05:42:53--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2019-08-02 05:42:53--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2019-08-02 05:42:53--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  24.1MB/s    in 36s     \n","\n","2019-08-02 05:43:30 (22.6 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zG4PHeCFxkA3","colab_type":"code","outputId":"7b7c749d-38ae-4af0-c3a8-b9bccf7e0df6","executionInfo":{"status":"ok","timestamp":1564724648625,"user_tz":-540,"elapsed":76143,"user":{"displayName":"군고구마","photoUrl":"https://lh5.googleusercontent.com/-I0XUuvaS1h0/AAAAAAAAAAI/AAAAAAAAAC4/1a-GQoFjqY4/s64/photo.jpg","userId":"10196243389166907276"}},"colab":{"base_uri":"https://localhost:8080/","height":149}},"source":["!pip3 install tensorflow-hub\n","!git clone https://github.com/stedy/Machine-Learning-with-R-datasets.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.7.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.16.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (41.0.1)\n","fatal: destination path 'Machine-Learning-with-R-datasets' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_owau2iivXHm","colab_type":"code","outputId":"0df1db9e-4c76-4c46-eada-a36cd5945df1","executionInfo":{"status":"ok","timestamp":1564724676169,"user_tz":-540,"elapsed":12258,"user":{"displayName":"군고구마","photoUrl":"https://lh5.googleusercontent.com/-I0XUuvaS1h0/AAAAAAAAAAI/AAAAAAAAAC4/1a-GQoFjqY4/s64/photo.jpg","userId":"10196243389166907276"}},"colab":{"base_uri":"https://localhost:8080/","height":448}},"source":["\n","import pandas as pd\n","data = pd.read_csv('Machine-Learning-with-R-datasets/sms_spam.csv', encoding='latin-1')\n","data[:5]\n","\n","# csv 데이터 label, sentence 구분\n","data['type'] = data['type'].replace(['ham','spam'],[0,1])\n","labels = list(data['type'])\n","texts = list(data['text'])\n","\n","#tokenizing the data\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","maxlen = 150\n","max_words = 10000 #consider only the top 10000 words in dataset\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)\n","word_index = tokenizer.word_index\n","print ('Found %s unique tokens.' %len(word_index))\n","\n","\n","data = pad_sequences(sequences, maxlen=maxlen)\n","labels = np.asarray(labels)\n","print ('Shape of data tensor:', data.shape)\n","print ('Shape of label tensor:', labels.shape)\n","\n","#splits the data into a training and validation set but first shuffles the data (because the data samples are ordered all negative first and then all positive)\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","\n","print(len(data))\n","training_samples = int(len(data) * 0.8)\n","validation_samples = int(len(data) - training_samples)\n","print(training_samples)\n","print(validation_samples)\n","\n","\n","x_train = data[:training_samples]\n","y_train = labels[:training_samples]\n","x_val = data[training_samples: training_samples + validation_samples]\n","y_val = labels[training_samples: training_samples + validation_samples]\n","\n","#parsing the Glove word-embeddings file\n","embeddings_index = {}\n","f = open('glove.6B.100d.txt')\n","for line in f:\n","\tvalues = line.split()\n","\tword = values[0]\n","\tcoefs = np.asarray(values[1:], dtype='float32')\n","\tembeddings_index[word] = coefs\n","f.close()\n","print ('Found %s word vectors.' %len(embeddings_index))\n","\n","#preparing the Glove word-embeddings matrix\n","embedding_dim = 100\n","embedding_matrix = np.zeros((max_words, embedding_dim))\n","for word, i in word_index.items():\n","\tif i < max_words:\n","\t\tembedding_vector = embeddings_index.get(word)\n","\t\tif embedding_vector is not None:\n","\t\t\tembedding_matrix[i] = embedding_vector\n","\n","#defining the model\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found 8995 unique tokens.\n","Shape of data tensor: (5574, 150)\n","Shape of label tensor: (5574,)\n","5574\n","4459\n","1115\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0802 05:44:34.682385 140128294324096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0802 05:44:34.697890 140128294324096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0802 05:44:34.700169 140128294324096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0802 05:44:34.742388 140128294324096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0802 05:44:34.762623 140128294324096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0802 05:44:34.768350 140128294324096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Found 400000 word vectors.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LZPwx2lGvugc","colab_type":"code","outputId":"b4b15993-c9a1-4425-8867-29e21bf5fae9","executionInfo":{"status":"ok","timestamp":1564726009853,"user_tz":-540,"elapsed":2904,"user":{"displayName":"군고구마","photoUrl":"https://lh5.googleusercontent.com/-I0XUuvaS1h0/AAAAAAAAAAI/AAAAAAAAAC4/1a-GQoFjqY4/s64/photo.jpg","userId":"10196243389166907276"}},"colab":{"base_uri":"https://localhost:8080/","height":112}},"source":["# 학습 진행\n","history = model.fit(x_train, y_train, epochs=1, batch_size=60)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["W0802 06:06:46.827710 140128294324096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","4459/4459 [==============================] - 2s 372us/step - loss: 0.2253 - acc: 0.9152\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WNZ_ExTsvvWp","colab_type":"code","outputId":"5391ec3f-8d08-445b-a1cf-d570c735c006","executionInfo":{"status":"ok","timestamp":1564726013122,"user_tz":-540,"elapsed":1127,"user":{"displayName":"군고구마","photoUrl":"https://lh5.googleusercontent.com/-I0XUuvaS1h0/AAAAAAAAAAI/AAAAAAAAAC4/1a-GQoFjqY4/s64/photo.jpg","userId":"10196243389166907276"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["# 모델 성능 비교.\n","print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(x_val, y_val)[1]))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1115/1115 [==============================] - 0s 72us/step\n","\n"," 테스트 정확도: 0.9767\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XJeJ06F98CfH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}