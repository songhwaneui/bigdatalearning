싸이킷 기반 기계학습

쉽다

gui 에저? 쉽다 =>유연성 떨어짐 커스터마이징힘듬

사이킷이 더좋다 캐글 70퍼 사이킷

어렵다.  데이터 이해도+ 통계+도메인+구현 코딩지식+수학=> 융합학문

구현 알고리즘 데이터처리

최소 데이터분석할려고 하면 학위가 필요하다-> 분석 석박사 남아돈다.

학위없어도 할려면 구현 잘해야 한다. 시스템 파이썬 느리다. //파이썬 -> c++, 자바 포팅하는 인력이 제일 부족
분석하는 사람은 많지만 시스템화하는 프로그래머는 적다.
취업자리코딩쪽이많다.
정부인식(코딩못하면 분석가)

구현잘하는사람 무조건 취업


왜 추천이 이렇게됬냐? 설명이 안됨 기계학습
따라서 설명도 되려면 통계쪽지식

딥러닝 의학쪽 접목 x  // 기계가 더 수술잘하지만 책임을 물을수 x 원인도 찾을수 x
윤리적 문제-> 설명가능하게할려고 통계  // 주제 다 빡꾸멕인다 의학쪽


분석 - 데이터 설명해줘야함

cs - 결과(예측정확도)에만 관심 => 중요 이슈 취업떄도 여기에 집중
성능이 좋아지면 대체
cs는 필요한곳에서만 움직임


NIPS 기계학습 최고학회

지도학습 => 클래스피케이션(적어서성능이좋음), 리그레이션 성능이 좋음

강화학습 => 불량품, 환경반응 -> 성능증가  제조업쪽 
기존 학습했던 모델 재학습-> 조금만 변화시키면 개학습시킨거 고양이도 학습가능

딥러닝 발전속도 엄청 빠르다
==================================================
기계학습 : 데이터로부터 구체적인 문제해결
기계학습은 일반화된 알고리즘 쓸 수 없다.
일반화된 모델(마스타 알고리즘)모든문제에 통용가능한 알고리즘을 만들수있따 주장! 책도있따 못만듬.
최적의 성능 모델 만들어야함

최적이라는건 unseened data 한번도 보지 않은 데이터에서 잘만드는게 기계학습의 목적

오버피팅시키면 성능이 떨어짐(결과예측)


결과와 떨어진 정도 = 바이어스


배리언스도 작을수록 바이어스도 작을수록 좋다. 데이터가  실제 모델 잘 이러지는 않다.


공식을 보면 바이어스 배리언스 트레이드 오프 관계 한쪽이 커지면 다른쪽은 작아진다. 2개다 작아질려고 하면 오차를 줄여야한다. 같은상황에서는 줄이기 어렵다.

우리는 적절한 상황에 맞는 모델을 만드어야하단다. 어렵다

바이어스 원래모델과 떨어진정도 배리언스? re실제값과 학습한 모델 값 차이

오차 엄청크면 오버피팅, 
대표성을 잘 표현할수 x 언더피팅
최적 오버 언더 사이

2개 합쳐가지고 가장 적절한 점을 찾는거 = 모델 셀렉션( 알고리즘을 따르게해서 or 모델내에서 변수를 바꿔서)

주제 관련 모델 알려줄거다

트레이닝 계쏙하면 학습에러는 줄고 테스트 에러는 는다.