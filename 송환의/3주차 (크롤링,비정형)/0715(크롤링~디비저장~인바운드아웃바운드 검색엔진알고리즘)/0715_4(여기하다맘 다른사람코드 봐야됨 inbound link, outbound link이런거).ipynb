{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import *\n",
    "from html import unescape\n",
    "import requests\n",
    "import json \n",
    "headers={\"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36\"}\n",
    "import requests\n",
    "import time\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "def download(method, url, \n",
    "             param = None, data = None, \n",
    "            timeout = 1,maxretries = 3):\n",
    "    \n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}\n",
    "    #headers = None\n",
    "    \n",
    "    try:\n",
    "        resp = requests.request(method, url, params= param, data=data, headers=headers)\n",
    "        resp.raise_for_status()\n",
    "        \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if 500 <= e.response.status_code < 600 and maxretries > 0: \n",
    "            time.sleep(timeout) # param에따라 몇초 기다릴지 결정 할 수가 있다.\n",
    "            print(maxretries) # 재귀적으로 자기 자신을 부르게 코드를 짜면 된다.\n",
    "            resp = download(method,\n",
    "                            url, param = param, data=data,\n",
    "                            timeout=timeout,\n",
    "                            maxretries = maxretries - 1)\n",
    "        else:\n",
    "            print(e.response.status_code)\n",
    "            print(e.response.reason)\n",
    "    return resp\n",
    "\n",
    "def checkBlog(url):\n",
    "    return requests.compat.urlparse(url)[1].endswith(\"tistory.com\")\n",
    "    ## 정규식 re.search(\".+?\\.tistory.com\", \"http:\\\\adam24eve.tistory.com/\") #짧게매칭되는거 ? 레이지 \n",
    "\n",
    "def parseURL(seed):\n",
    "    html = download(\"get\",seed)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    \n",
    "    ## naver iframe html안에 html 또들어있어서\n",
    "   # if len(dom.select(\"#mainFrame\")) < 1:  ## 메인이랑, 첫페이지만 없음\n",
    "   #     return []\n",
    "    \n",
    "   \n",
    "   # seed = requests.compat.urljoin(seed,dom.select(\"#mainFrame\")[0][\"src\"])\n",
    "  #  print(\"-=================================================\")\n",
    "   # print(seed)\n",
    "  #  print(\"-=================================================\")\n",
    "   # html = download(\"get\",seed)\n",
    "   # dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    \n",
    "\n",
    "    return  [requests.compat.urljoin(seed, _[\"href\"]) for _ in dom.find_all(\"a\") if  _.has_attr(\"href\") and len(_[\"href\"]) >3 ]\n",
    "\n",
    "##and checkBlog(requests.compat.urljoin(seed, _[\"href\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## url을 pk값으로 삼으면 안됨 문자열로 삼으면 안된다  => 해시값을 못만든다.  인덱싱하는데 느려진다. pk제대로 못걸르고\n",
    "# 언제 엑세싱했는지 처음방문했는지 data값 필요\n",
    "# seen 내가 본앤지 아닌지 검사하는 \n",
    "# =>> 최소 4개 컬럼 id, url, seen, data\n",
    "# 특정 url 해당되는 애들만 쓰고싶으면 \n",
    "\n",
    "## 스크랩파이 내부구조를 배우는중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b267df4b3c3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtable1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# url path만 있고 파라메터값 쿼리 넣어서 돌린다. t1과 , t2를 조인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtable2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 특정도메인만 관리하는 테이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "table1 = id, url, seen, date\n",
    "# url path만 있고 파라메터값 쿼리 넣어서 돌린다. t1과 , t2를 조인\n",
    "table2 = id, netloc, date\n",
    "# 특정도메인만 관리하는 테이블\n",
    "\n",
    "url = netloc + path + param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect(\"bot6.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.executescript(\"\"\"\n",
    "    DROP TABLE IF EXISTS table1;\n",
    "    CREATE TABLE table1(\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "        table2_id INTEGER NOT NULL,\n",
    "        path TEXT NOT NULL,\n",
    "        param TEXT ,\n",
    "        seen BOOLEAN DEFAULT FALSE NOT NULL,\n",
    "        date TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL\n",
    "    );\n",
    "    \n",
    "    DROP TABLE IF EXISTS table2;\n",
    "    CREATE TABLE table2(\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "        netloc TEXT NOT NULL,\n",
    "        date TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL\n",
    "    );\n",
    "\n",
    "\"\"\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 실제 입력하는 PATHH PARAM 본적있으면 seen => true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ko.wikipedia.org\n",
      "(1,)\n",
      "9 (1,)\n",
      "https://ko.wikipedia.org\n",
      "(1,)\n",
      "10 (1,)\n",
      "https://news.joins.com\n",
      "(2,)\n",
      "11 (2,)\n",
      "https://twitter.com\n",
      "(3,)\n",
      "12 (3,)\n",
      "https://movie.daum.net\n",
      "(4,)\n",
      "13 (4,)\n",
      "http://m.cafe.daum.net\n",
      "(5,)\n",
      "14 (5,)\n",
      "https://www.msn.com\n",
      "(6,)\n",
      "15 (6,)\n",
      "https://www.msn.com\n",
      "(6,)\n",
      "16 (6,)\n"
     ]
    }
   ],
   "source": [
    "# Seed URLs  -> DB Insert \n",
    "url = \"https://www.google.com/search\"\n",
    "html = download(\"get\",url, param={\"q\":\"박보영\"})\n",
    "dom = BeautifulSoup(html.text, \"lxml\")\n",
    "\n",
    "for href in [_.find_parent()[\"href\"] for _ in dom.select(\".LC20lb\")]:\n",
    "    \n",
    "    _urlparse = requests.compat.urlparse(href)\n",
    "  \n",
    "    netloc = \"://\".join(_urlparse[:2])  ## 0과 1 합침\n",
    "    ## print(netloc)\n",
    "    cur.execute(\"SELECT id FROM table2 WHERE netloc = ? LIMIT 0,1\", [netloc]) ## re!! limit 0,1 이랑 fetchone()랑 차이가 뭐냐??\n",
    "    netlocID = cur.fetchone()\n",
    "    print(netlocID)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    \n",
    "    if not netlocID: \n",
    "        cur.execute(\"INSERT INTO table2(netloc) VALUES(?)\", [netloc])\n",
    "        con.commit()\n",
    "        cur.execute(\"SELECT id FROM table2 WHERE netloc=?  LIMIT 0,1\", [netloc])\n",
    "\n",
    "        netlocID =cur.fetchone()\n",
    "        print(netlocID[0])\n",
    "        print(\"--\")\n",
    "    cur.execute(\"INSERT INTO table1(table2_id, path, param) VALUES(?,?,?)\", [netlocID[0], _urlparse[2], _urlparse[4]])\n",
    "    con.commit()  ## 여기까지하면 큐가 생성되어있다.\n",
    "    print(cur.lastrowid, netlocID)\n",
    "       # DB Select Limit 0,1 하면 SELECT 해서 여러개 있는거중에서  위에 있는거 하나만 가져오는거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 여기부터 re!! db만들고, seed를 튜플로 둬서 depth , inbound 까지도 db에 저장하는것까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n",
      "(1, 'https://ko.wikipedia.org', '/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', '')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4e5780e3a64b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                    \u001b[0mORDER\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mtable1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[0mASC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                    ; \"\"\")\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    cur.execute(\"\"\"SELECT table1.id, table2.netloc, table1.path, table1.param\n",
    "                   FROM table1\n",
    "                   JOIN table2\n",
    "                  ON table1.table2_id=table2.id\n",
    "                   WHERE table1.seen='FALSE'\n",
    "                   \n",
    "                   ORDER BY table1.date ASC \n",
    "                   ; \"\"\")\n",
    "    time.sleep(1)\n",
    "    seed = cur.fetchone()\n",
    "    if not seed or i > 100:\n",
    "        break;\n",
    "    i+1\n",
    "    print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseURL(seed):\n",
    "    html = download(\"get\",seed[0])\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    \n",
    "\n",
    "    return  [(requests.compat.urljoin(seed[0], _[\"href\"]),seed[1]+1)\n",
    "             for _ in dom.find_all(\"a\") \n",
    "             if seed[1] < 2 and  _.has_attr(\"href\") and len(_[\"href\"]) >3 and checkBlog(requests.compat.urljoin(seed[0], _[\"href\"]))]\n",
    "# 뎁스를 2까지만 하겠다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = list() ##하나 생김\n",
    "queue.extend( [(_[\"href\"],1) for _ in dom.select(\".LC201b\") if checkBlog(_[\"href\"])])\n",
    "seen = list()\n",
    "while queue :\n",
    "    baseURL = queue.pop(0)  ##지금 너비우선\n",
    "                            ##pop(0)을 깊이우선 -1로 바꿔서 depth 를 정해놓고 or 특정도메인내에서만 => 포커스드크롤링\n",
    "    print(baseURL)\n",
    "    seen.append(baseURL)\n",
    "    # 슬립 \n",
    "    time.sleep(1)\n",
    "    linkList = parseURL(baseURL) # 중복된 url 계속 생김 re??\n",
    " \n",
    "    for link in linkList:\n",
    "        if link not in queue and link not in seen:\n",
    "            queue.append(link)\n",
    "    print(\"Queue: {0}, Seen: {1}\".format(len(queue), len(seen)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
