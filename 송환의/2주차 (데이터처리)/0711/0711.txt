0711 opt-out 방식 합법 전세계적으로 명시적 거부만 중단 나머지 다 가져감
특정집단의 이익 대변 x => 공익우선
합법이다. 공익이다 우기면됨 ex) 다른데서 정보 가져와서 제주항공 가격비교 제공해준다, 구글검색엔진
봇 행동 규약 파악 => 위법아함
 
불법이다 .  

ex)  봇 대신 회원가입 -> 서버에 데이터 리퀘스트   db에있는 저작권다가져올수 있음 ex) 유료사이트 정보제공서버 
ex) 사람은 게시물 읽고 하는데 오래걸림 리퀘스트 10번

봇은 html받기만 하면 이동, 렌더링 안와도 1초에 여러번씩 리퀘스트 10000번, 트래픽 봇이 차지 => 정상 서비스 못함
봇,트로이목마

ex) 이런식으로 이메일 털렷었음 -> 스팸
   개인정보 동의 -> 봇이털어감 데이터

자료를 받아서 딴데 배포하면 안됨
코드 내가짜고 나만데이터가지고있음됨

개인정보, 지적재산권 노출되면 안됨
flash 쓰는 그런 민박사이트 => 개인정보다노출됨 폰,이메일,장소 => 다불법 


이용방침
우리사이트 봇쓰지마세요 이런거 , 모든 사이트 개인정보보호방침, 사이트이용방침 링크있는데 -> 본사이트는 당신개인정보 ~~수집 ~어떻게이용~ 이런거 써잇음
자동화된프로그램으로 데이터 수집 안됩니다.
opt out 으로 가져오면 약관안읽은 잘못

개인의 영달이 아니라 공익의 목적으로 내가짠 코드로 나만 데이터 이용

==================================================

잡코리아 업계1위 회사평, 연봉정보, 사람많음 1위 => db화해서 관리(저작물)
사람인 봇 만들어서 직접들어가진 않고, 네이버에서 검색하면 나오는 잡코리아에서 나오는 정보 검색
네이버는 공적인 목적 써도된다. but 내가 그걸로 쓰면 문제가됨 남의꺼쓰니까

사람인 자기거인마냥 데이터 씀

청년들 올해 정권 창업좋다 여성창업,내년은모르겠다
=======================================================
국내에서 제일남 숙박업소 
야놀자업계1위, 가맹점 더많음
여기어때2위, cf)여기어때대표
숙박업소 정보 중요 
어떤 서비스 새로하고싶다 -> 가장 잘나가는데 카피해서 오픈
 opt-out 임에도 불구하고 문제인 부분


트래픽 리퀘스트너무안보내고
저작권 우리가 상업이용  x
이용방침

맑은고딕 폰트 이런거도 저작권 있다 (개인한테만 허락. but 웹만들면 불법)

사이트뒤에
robots.txt 대로만 하면 최소한의것들 다지키는것


User-agent: *  ## 특정봇에대해서는 허용 *는 모든 봇
Disallow: /    ##루트 밑에 다 허락안한다 사이트 다 긁어가면안된다. allow : / 면 다긁어가도된다.
Allow : /$ 

robots.txt 없으면 -> 맘대로 opt -out식으로 가져가도 된다.



서버로그엔 누가access log에 누가 들어왓냐 나갓냐 다뜬다

user-agent 값에 봇이면 봇, 사용자면 ip, 어떤브라우져 어떤페이지봣냐 다뜸

서버운영하다보면
예티 들어옴 네이버봇 => 데이터 가져감
 robots.txt 했는데 가져갔다 -> 고소하면됨

개인은 관리안해서 상관없는데 변태한테걸리면 가져가다가 고소 걸릴수있음
따라서 대형포탈사이트 위주로 턴다

/robots.txt 없으면 페이지만드는데 돈안씀 항공대





민감한정보, 저작권, , robots.txt확인, 이용방침 준수, 크롤링 너무많이 x


builtwith => 어떤기술프레임워크 써서 만들었는지 알수있음(국내네이버 이런건 ping 막아놈 쫄보)

whois : 소유자가 누군지


urlib http 상위계층 http 감싸고있음
urllib.request 리퀘스트 인스턴스 만듬(http담아서, 호스트누구, 원하는 페이지, 파레메터 등등)
urllib open 해서 서버로 보내고

http에 담아와서 응답온거 urllib.response 한번읽으면 끝 버퍼날려서 

앵커 - 링크 
외부링크 내부링크

리퀘스트 호스트부터시작해서 전체주소 parsing을 통해서 url 만들어주고

robotparser 로 txt file 긁어와서  true false 가져옴 => can_fetch


로봇파서 => 긁어올수있는지 없는지 대답



url 바뀌면 인스턴스 다시만들어야함 







?뒤에는 파라메터

한글은 %ed이런식으로 hexadecimal 16진코드의 값으로 날라감 percent_encoding(한글을 바이트단위로 인코딩)

우리가 읽을때는 16진코드  -> 한글로 바꾸는 디코딩 필요  




client error 내잘못
500 에러 => 서버잘못 일시적으로 서버 응답 못하는 상황 터질랑 말랑 하는거 이러면 500 time가져와서 slip 시간 둬서 기다렷다가 다시해보고 이러면됨

서버가 아예터져버리면 404 계쏙 기다려도 안됨
따라서  status code 분기해서 작업

나중에 티케팅자동되는거 해볼거



robots.txt  * allow , 경로 설정 이거 다시 re!! 

=================================================


