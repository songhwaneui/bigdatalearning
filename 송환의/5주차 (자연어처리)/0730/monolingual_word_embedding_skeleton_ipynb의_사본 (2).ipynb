{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "monolingual_word_embedding_skeleton.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL5eq6P1-COr",
        "colab_type": "text"
      },
      "source": [
        "# **Github project download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VuYe71yq__Z",
        "colab_type": "code",
        "outputId": "beead36a-d6bf-432d-a4bd-7e8499925a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "## 사본만들어야 수정 가능\n",
        "## 전처리는 되어있으나 형태소 분석 x o\n",
        "## 어제 배운거로 형태소 분석 해보면 됨\n",
        "import os.path\n",
        "\n",
        "if os.path.isdir('./korean_word_embedding_tutorial') == 'True':  \n",
        "  !rm -r ./korean_word_embedding_tutorial\n",
        "  !git clone https://github.com/sseol11/korean_word_embedding_tutorial\n",
        "else: \n",
        "  !git clone https://github.com/sseol11/korean_word_embedding_tutorial"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'korean_word_embedding_tutorial'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 41 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKmxPsx_rhd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir korean_word_embedding_tutorial/training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPMhp4rrJCIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm korean_word_embedding_tutorial/training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cybogIcb-MuL",
        "colab_type": "text"
      },
      "source": [
        "# **Training data download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEMBwpqR187a",
        "colab_type": "code",
        "outputId": "58518d60-be6c-44ef-a98e-562fc274bdae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "#!wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1SaIMXjnsCHakT7sDo2ATaUUZb1k9x3No' -O pos_remove_wiki_ko.txt\n",
        "## 구글드라이브는 위에 html코드가 붙어서 전처리 작업이 필요하다\n",
        "!wget \"https://www.dropbox.com/s/ozcb1b0mwlp4g2h/pos_remove_wiki_ko_1000k.txt?dl=0\" -O pos_remove_wiki_ko.txt\n",
        "!mv pos_remove_wiki_ko.txt ./korean_word_embedding_tutorial/training_data\n",
        "\n",
        "## 형태소 분석까지 다 된거 받음"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-30 04:30:10--  https://www.dropbox.com/s/ozcb1b0mwlp4g2h/pos_remove_wiki_ko_1000k.txt?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ozcb1b0mwlp4g2h/pos_remove_wiki_ko_1000k.txt [following]\n",
            "--2019-07-30 04:30:10--  https://www.dropbox.com/s/raw/ozcb1b0mwlp4g2h/pos_remove_wiki_ko_1000k.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca2400c3f55e1d3308800110e18.dl.dropboxusercontent.com/cd/0/inline/AlpLOFPNmGMEw1YZfMCBf_Zc0yguQoaf9iQ6fwBmw44IiZVJOIeUNZPvJw1_pJmfsZZTNFiKbpzWFe5aLpHKwPQi_-TLcL1ShxPcH0qZyJvRVQ/file# [following]\n",
            "--2019-07-30 04:30:10--  https://uca2400c3f55e1d3308800110e18.dl.dropboxusercontent.com/cd/0/inline/AlpLOFPNmGMEw1YZfMCBf_Zc0yguQoaf9iQ6fwBmw44IiZVJOIeUNZPvJw1_pJmfsZZTNFiKbpzWFe5aLpHKwPQi_-TLcL1ShxPcH0qZyJvRVQ/file\n",
            "Resolving uca2400c3f55e1d3308800110e18.dl.dropboxusercontent.com (uca2400c3f55e1d3308800110e18.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to uca2400c3f55e1d3308800110e18.dl.dropboxusercontent.com (uca2400c3f55e1d3308800110e18.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 160376859 (153M) [text/plain]\n",
            "Saving to: ‘pos_remove_wiki_ko.txt’\n",
            "\n",
            "pos_remove_wiki_ko. 100%[===================>] 152.95M  48.6MB/s    in 3.1s    \n",
            "\n",
            "2019-07-30 04:30:14 (48.6 MB/s) - ‘pos_remove_wiki_ko.txt’ saved [160376859/160376859]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn7E1fuCL5S_",
        "colab_type": "code",
        "outputId": "f1c3072a-759d-4e47-b56e-2622939da9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!wc -l ./korean_word_embedding_tutorial/training_data/pos_remove_wiki_ko.txt\n",
        "\n",
        "## 라인이 100만줄"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000000 ./korean_word_embedding_tutorial/training_data/pos_remove_wiki_ko.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSjoYzIjiJHm",
        "colab_type": "text"
      },
      "source": [
        "# Environment check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-qjHvyvM2hq",
        "colab_type": "code",
        "outputId": "12cda6a4-04c9-44e5-fecb-0d63e3ef51b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Core(s) per socket:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYuh70blM3ZT",
        "colab_type": "code",
        "outputId": "bb960115-bcae-4179-aad8-5e9160bcb8da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#no.of threads each core is having\n",
        "!lscpu | grep 'Thread(s) per core'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread(s) per core:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv0jWNMRF2Tg",
        "colab_type": "text"
      },
      "source": [
        "# **1. Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwokUjrGF9tZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import word2vec\n",
        "import logging\n",
        "## 진심 cpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfTZzu8sGCRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # import modules & set up logging\n",
        "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "    # read sentences, Iterate over a file that contains sentences # 파일을 병렬적으로 읽어온다.\n",
        "    sentences = word2vec.LineSentence('./korean_word_embedding_tutorial/training_data/pos_remove_wiki_ko.txt')\n",
        "    \n",
        "    # train word2vec, sg=1 : skip-gram // workers : parallelization  #학습 , 선험적 지식으로 파라메터 설정\n",
        "    # apple 0.1 -0.5 , 0.6, ..... 이런거 단위를 300정도로\n",
        "    model = word2vec.Word2Vec(sentences, window=5, sg=1, size=300, workers=2)\n",
        "    \n",
        "    # model save\n",
        "    # cpkt 모델\n",
        "    model.save(\"./korean_word_embedding_tutorial/wiki_ko_model.cpkt\") \n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9qsK0J2G6uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_example():\n",
        "    try:\n",
        "      model = word2vec.Word2Vec.load(\"./korean_word_embedding_tutorial/wiki_ko_model\")\n",
        "      vector = model.wv['서울'] ## 서울이라는 단어에 대한 워드 벡터출력 -> 위치 잘몰라서 비주얼라이제이션\n",
        "      print(vector)\n",
        "    except KeyError:\n",
        "      print(\"This word not in vocabulary\")\n",
        "    \n",
        "    try:\n",
        "      target_word = ['서울']\n",
        "      print(model.wv.most_similar(positive=target_word, topn=6)) ## 서울에 가장 근접한거 6개\n",
        "    \n",
        "    except KeyError:\n",
        "      print(\"This word not in vocabulary\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTCymYWrG2oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        " #   main()\n",
        "     model_example()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsqMNikyRR8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  ('부산', 0.6782873272895813)  코사인 시밀러리티 부산이 값이 얼마나 유사하다 이ㅓㄴ거"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_vZmwnHHogU",
        "colab_type": "text"
      },
      "source": [
        "# 1.1 Pretrained model (부가사항)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7ABKzqVIYZd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*  **2430k lines wikipedia korea data pretrained model**\n",
        "*  **본 실습모델보다 학습량이 많은 모델**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd5NkFLbHoHO",
        "colab_type": "code",
        "outputId": "e2e2f55b-8323-4c00-f6ae-040e2e4d4d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "source": [
        "!mkdir ./korean_word_embedding_tutorial/pre_trained_model\n",
        "!wget \"https://www.dropbox.com/sh/bvvj3c650zshaju/AADfgmvxx_A6PvaxuaE5GNQka?dl=0\" -O pre_trained_model.zip\n",
        "!unzip pre_trained_model.zip -d ./korean_word_embedding_tutorial/pre_trained_model/\n",
        "!rm pre_trained_model.zip\n",
        "\n",
        "## 2천4백만 이게 존나 많음\n",
        "# 지금 우리가한건 100백만개 이정도"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./korean_word_embedding_tutorial/pre_trained_model’: File exists\n",
            "--2019-07-23 14:09:22--  https://www.dropbox.com/sh/bvvj3c650zshaju/AADfgmvxx_A6PvaxuaE5GNQka?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:6031:1::a27d:5101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/bvvj3c650zshaju/AADfgmvxx_A6PvaxuaE5GNQka [following]\n",
            "--2019-07-23 14:09:22--  https://www.dropbox.com/sh/raw/bvvj3c650zshaju/AADfgmvxx_A6PvaxuaE5GNQka\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc7b17222e470c13808c323dcc3e.dl.dropboxusercontent.com/zip_by_token_key?key=AlO15CZZWtv5Pqka-YruTsrffStxz8KRrs6PI-3jEf0J3y-kwzne_AdrpjgApNNA2mifhGS-lP2fGvubN0X3V4I1ZgwPwXsUtRBL--h7P2TvteyerPIuL97F0RbdmB_NGl86eIrlivHoGQC8mzUUdys3r0Ram6esB0h42Kbzw9AeajHXgfvj7B9s6FyWtY7U9UhM73r1qQVkNYSS4OdL-R9mgkd0TW6yh1Q3zlpm9_ox4fGqQbKfxTcJB-tIAIIY-Gh491R0BPFx7-U1aXbvQ-f0BkuLKphF-6XqdeQp9iT0Fk6K6dVq_Jw9Pex04RDlag0vDx_8jAfKW9aOv8POeVYzhPyjEcf6hvbkDq-BfLBG8w [following]\n",
            "--2019-07-23 14:09:22--  https://uc7b17222e470c13808c323dcc3e.dl.dropboxusercontent.com/zip_by_token_key?key=AlO15CZZWtv5Pqka-YruTsrffStxz8KRrs6PI-3jEf0J3y-kwzne_AdrpjgApNNA2mifhGS-lP2fGvubN0X3V4I1ZgwPwXsUtRBL--h7P2TvteyerPIuL97F0RbdmB_NGl86eIrlivHoGQC8mzUUdys3r0Ram6esB0h42Kbzw9AeajHXgfvj7B9s6FyWtY7U9UhM73r1qQVkNYSS4OdL-R9mgkd0TW6yh1Q3zlpm9_ox4fGqQbKfxTcJB-tIAIIY-Gh491R0BPFx7-U1aXbvQ-f0BkuLKphF-6XqdeQp9iT0Fk6K6dVq_Jw9Pex04RDlag0vDx_8jAfKW9aOv8POeVYzhPyjEcf6hvbkDq-BfLBG8w\n",
            "Resolving uc7b17222e470c13808c323dcc3e.dl.dropboxusercontent.com (uc7b17222e470c13808c323dcc3e.dl.dropboxusercontent.com)... 162.125.66.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to uc7b17222e470c13808c323dcc3e.dl.dropboxusercontent.com (uc7b17222e470c13808c323dcc3e.dl.dropboxusercontent.com)|162.125.66.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘pre_trained_model.zip’\n",
            "\n",
            "pre_trained_model.z     [             <=>    ] 418.05M  12.5MB/s    in 39s     \n",
            "\n",
            "2019-07-23 14:10:03 (10.6 MB/s) - ‘pre_trained_model.zip’ saved [438354035]\n",
            "\n",
            "Archive:  pre_trained_model.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            "  inflating: ./korean_word_embedding_tutorial/pre_trained_model/wiki_ko_model.wv.syn0.npy  \n",
            "  inflating: ./korean_word_embedding_tutorial/pre_trained_model/wiki_ko_model_129512_300d_labels.tsv  \n",
            "  inflating: ./korean_word_embedding_tutorial/pre_trained_model/wiki_ko_model.syn1neg.npy  \n",
            "  inflating: ./korean_word_embedding_tutorial/pre_trained_model/wiki_ko_model_129512_300d_tensors.bytes  \n",
            "  inflating: ./korean_word_embedding_tutorial/pre_trained_model/wiki_ko_model  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvo-_S4BRyaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# _129512_300d_tensors.bytes  \n",
        "# 129512_300d_labels.tsv   비주얼라이제이션 할때 쓰는거\n",
        "## https://github.com/sseol11/korean_word_embedding_tutorial 여기서 배포한거 한국어처리 이거 쓰면 된다.\n",
        "##"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7UBZdo6bvlV",
        "colab_type": "text"
      },
      "source": [
        "# 2. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNdU7Ilxbyff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ./korean_word_embedding_tutorial/visualization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr-DQxQhSazA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZscUxKub09U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM8SbQ3_b2HR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = './korean_word_embedding_tutorial/'\n",
        "\n",
        "def main():\n",
        "    model = Word2Vec.load(root_path + 'wiki_ko_model')\n",
        "    \n",
        "    try:\n",
        "      num_rows = len(model.vocab)\n",
        "    except:\n",
        "      model.vocab = model.wv.vocab\n",
        "      num_rows = len(model.vocab)\n",
        "      \n",
        "    dim = model.vector_size\n",
        "    \n",
        "    global tensor_out_fn\n",
        "    global labels_out_fn\n",
        "    \n",
        "    tensor_out_fn = root_path + 'visualization/wiki_ko_model_%d_%dd_tensors.tsv' % (num_rows, dim)\n",
        "    labels_out_fn = root_path + 'visualization/wiki_ko_model_%d_%dd_labels.tsv' % (num_rows, dim)\n",
        "    \n",
        "    \n",
        "    try:\n",
        "      labels_out = open(labels_out_fn, 'w', encoding='utf-8')\n",
        "    except:\n",
        "      labels_out = open(labels_out_fn, 'w')\n",
        "      \n",
        "    labels_out.write(\"word\\tlanguage\\tcount\\n\") ## 바이링규얼은 언어끼리 구분해야 좋다.\n",
        "    wv_list=[]\n",
        "    \n",
        "    counter = {}\n",
        "    for wd in model.vocab:\n",
        "      counter[wd] = model.vocab[wd].count\n",
        "    counter = Counter(counter)\n",
        "    common = counter.most_common(5000) #cpu써서 많이하면 뒤진다. 상위 5천건\n",
        "    words, _ = zip(*common)\n",
        "    \n",
        "    for wd in words:\n",
        "      ww = model[wd].tolist()\n",
        "      assert dim == len(ww)\n",
        "      assert '\\t' not in wd\n",
        "      wv_list.append(ww)\n",
        "      \n",
        "      try:\n",
        "        labels_out.write('%s\\t%s\\t%s\\n' % (wd, 'ko', model.vocab[wd].count))\n",
        "      except:\n",
        "        labels_out.write('%s\\t%s\\t%s\\n' % (wd, 'ko', model.vocab[wd].count)).encode('utf-8')\n",
        "        \n",
        "    with open(tensor_out_fn, 'w') as fw:\n",
        "      for i in wv_list:\n",
        "        fw.write(\"%s\\n\" % (str(i).replace(', ', '\\t').replace('[', '').replace(']', '')))\n",
        "    \n",
        "    labels_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdSOp0pPb4Pb",
        "colab_type": "code",
        "outputId": "86234442-4fd4-437b-82c1-ef2fd8de13d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "if __name__ ==\"__main__\":\n",
        "    main()\n",
        "    \n",
        "    "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-30 05:26:37,003 : INFO : loading Word2Vec object from ./korean_word_embedding_tutorial/wiki_ko_model\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-07-30 05:26:37,333 : INFO : loading wv recursively from ./korean_word_embedding_tutorial/wiki_ko_model.wv.* with mmap=None\n",
            "2019-07-30 05:26:37,334 : INFO : loading vectors from ./korean_word_embedding_tutorial/wiki_ko_model.wv.vectors.npy with mmap=None\n",
            "2019-07-30 05:26:37,375 : INFO : setting ignored attribute vectors_norm to None\n",
            "2019-07-30 05:26:37,376 : INFO : loading vocabulary recursively from ./korean_word_embedding_tutorial/wiki_ko_model.vocabulary.* with mmap=None\n",
            "2019-07-30 05:26:37,378 : INFO : loading trainables recursively from ./korean_word_embedding_tutorial/wiki_ko_model.trainables.* with mmap=None\n",
            "2019-07-30 05:26:37,379 : INFO : loading syn1neg from ./korean_word_embedding_tutorial/wiki_ko_model.trainables.syn1neg.npy with mmap=None\n",
            "2019-07-30 05:26:37,417 : INFO : setting ignored attribute cum_table to None\n",
            "2019-07-30 05:26:37,419 : INFO : loaded ./korean_word_embedding_tutorial/wiki_ko_model\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUwuf72xWZ2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 1-코사인 시뮬러리티 = 코사인 디스턴스 작을수로 가깝다"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aftxxKcHif65",
        "colab_type": "text"
      },
      "source": [
        "# [Embedding projector](http://projector.tensorflow.org/)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "![대체 텍스트](https://miro.medium.com/max/1200/1*Fat62b1ZITOFMPXTcHNkLw.jpeg)"
      ]
    }
  ]
}