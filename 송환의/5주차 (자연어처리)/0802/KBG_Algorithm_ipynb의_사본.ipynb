{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KBG_Algorithm.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eayGXBuJaCK",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/AbdulDridi/Knowledge-Based-WSD\n",
        "이 소스는 위의 github주소에 기반합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti8m-hdy4Wyy",
        "colab_type": "code",
        "outputId": "825d9309-5706-4566-fbc7-db479d162f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 uninstall numpy\n",
        "!pip3 install folium==0.2.1\n",
        "!pip3 install imgaug==0.2.5\n",
        "!pip3 install --upgrade numpy==1.16.1\n",
        "!pip3 freeze ## 파이썬 패키지 설치된거 버전 몇인지 보여줌"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling numpy-1.16.4:\n",
            "  Would remove:\n",
            "    /usr/bin/f2py\n",
            "    /usr/bin/f2py3\n",
            "    /usr/bin/f2py3.6\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.6\n",
            "    /usr/local/lib/python3.6/dist-packages/numpy-1.16.4.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/numpy/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled numpy-1.16.4\n",
            "Collecting folium==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from folium==0.2.1) (2.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-cp36-none-any.whl size=79980 sha256=24806d38ed7889cda65e62dcb670bd01a5cc5a63030c3dcee6a6b8a834603f98\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n",
            "Collecting imgaug==0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/60/a06a48d85a7e9062f5870347a3e3e953da30b37928d43b380c949bca458a/imgaug-0.2.5.tar.gz (562kB)\n",
            "\u001b[K     |████████████████████████████████| 563kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.5) (1.3.0)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.5) (0.15.0)\n",
            "Collecting numpy>=1.7.0 (from imgaug==0.2.5)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/b9/bda9781f0a74b90ebd2e046fde1196182900bd4a8e1ea503d3ffebc50e7c/numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
            "\u001b[K     |████████████████████████████████| 20.4MB 43.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.5) (1.12.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (3.0.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (4.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.5) (4.4.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (41.0.1)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.5-cp36-none-any.whl size=561441 sha256=bce5e709458435bc167affa831ec1d2d752b36f580eb04001199b28f9c995628\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/48/c8/ca3345e8582a078de94243996e148377ef66fdb845557bae0b\n",
            "Successfully built imgaug\n",
            "Installing collected packages: numpy, imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.2.5 numpy-1.17.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.17.0\n",
            "    Uninstalling numpy-1.17.0:\n",
            "      Successfully uninstalled numpy-1.17.0\n",
            "Successfully installed numpy-1.16.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.7.1\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==3.1.0\n",
            "astor==0.8.0\n",
            "astropy==3.0.5\n",
            "atari-py==0.1.15\n",
            "atomicwrites==1.3.0\n",
            "attrs==19.1.0\n",
            "audioread==2.1.8\n",
            "autograd==1.2\n",
            "Babel==2.7.0\n",
            "backcall==0.1.0\n",
            "backports.tempfile==1.0\n",
            "backports.weakref==1.0.post1\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.1.0\n",
            "blis==0.2.4\n",
            "bokeh==1.0.4\n",
            "boto==2.49.0\n",
            "boto3==1.9.189\n",
            "botocore==1.12.189\n",
            "Bottleneck==1.2.1\n",
            "branca==0.3.1\n",
            "bs4==0.0.1\n",
            "bz2file==0.98\n",
            "cachetools==3.1.1\n",
            "certifi==2019.6.16\n",
            "cffi==1.12.3\n",
            "chainer==5.4.0\n",
            "chardet==3.0.4\n",
            "Click==7.0\n",
            "cloudpickle==0.6.1\n",
            "cmake==3.12.0\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.1.3\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.14.6\n",
            "cvxopt==1.2.3\n",
            "cvxpy==1.0.15\n",
            "cycler==0.10.0\n",
            "cymem==2.0.2\n",
            "Cython==0.29.12\n",
            "daft==0.0.4\n",
            "dask==1.1.5\n",
            "dataclasses==0.6\n",
            "datascience==0.10.6\n",
            "decorator==4.4.0\n",
            "defusedxml==0.6.0\n",
            "descartes==1.1.0\n",
            "dill==0.3.0\n",
            "distributed==1.25.3\n",
            "Django==2.2.3\n",
            "dlib==19.16.0\n",
            "dm-sonnet==1.34\n",
            "docopt==0.6.2\n",
            "docutils==0.14\n",
            "dopamine-rl==1.0.5\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.1.0\n",
            "entrypoints==0.3\n",
            "ephem==3.7.6.0\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.55\n",
            "fastcache==1.1.0\n",
            "fastdtw==0.3.2\n",
            "fastprogress==0.1.21\n",
            "fastrlock==0.4\n",
            "fbprophet==0.5\n",
            "feather-format==0.4.0\n",
            "featuretools==0.4.1\n",
            "filelock==3.0.12\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.1\n",
            "folium==0.2.1\n",
            "fsspec==0.3.2\n",
            "future==0.16.0\n",
            "gast==0.2.2\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.49\n",
            "geopy==1.17.0\n",
            "gevent==1.4.0\n",
            "gin-config==0.2.0\n",
            "glob2==0.7\n",
            "google==2.0.2\n",
            "google-api-core==1.13.0\n",
            "google-api-python-client==1.7.9\n",
            "google-auth==1.4.2\n",
            "google-auth-httplib2==0.0.3\n",
            "google-auth-oauthlib==0.4.0\n",
            "google-cloud-bigquery==1.14.0\n",
            "google-cloud-core==1.0.2\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.16.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.1.7\n",
            "google-resumable-media==0.3.2\n",
            "googleapis-common-protos==1.6.0\n",
            "googledrivedownloader==0.4\n",
            "graph-nets==1.0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==0.4.15\n",
            "grpcio==1.15.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.2\n",
            "gunicorn==19.9.0\n",
            "gym==0.10.11\n",
            "h5py==2.8.0\n",
            "HeapDict==1.0.0\n",
            "holidays==0.9.10\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.16\n",
            "httplib2==0.11.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.8\n",
            "image==1.5.27\n",
            "imageio==2.4.1\n",
            "imagesize==1.1.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.5\n",
            "importlib-metadata==0.19\n",
            "imutils==0.5.2\n",
            "inflect==2.1.0\n",
            "intel-openmp==2019.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.6.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.5.0\n",
            "itsdangerous==1.1.0\n",
            "jdcal==1.4.1\n",
            "jedi==0.14.1\n",
            "jieba==0.39\n",
            "Jinja2==2.10.1\n",
            "jmespath==0.9.4\n",
            "joblib==0.13.2\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.1\n",
            "jupyter-console==6.0.0\n",
            "jupyter-core==4.5.0\n",
            "kaggle==1.5.4\n",
            "kapre==0.1.3.1\n",
            "Keras==2.2.4\n",
            "Keras-Applications==1.0.8\n",
            "Keras-Preprocessing==1.1.0\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.1.0\n",
            "knnimpute==0.1.0\n",
            "librosa==0.6.3\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.29.0\n",
            "lmdb==0.96\n",
            "lucid==0.3.8\n",
            "lunardate==0.2.0\n",
            "lxml==4.2.6\n",
            "magenta==0.3.19\n",
            "Markdown==3.1.1\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.0.3\n",
            "matplotlib-venn==0.11.5\n",
            "mesh-tensorflow==0.0.5\n",
            "mido==1.2.6\n",
            "mir-eval==0.5\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.5.4\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==7.1.0\n",
            "moviepy==0.2.3.5\n",
            "mpi4py==3.0.2\n",
            "mpmath==1.1.0\n",
            "msgpack==0.5.6\n",
            "multiprocess==0.70.8\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.2\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbconvert==5.5.0\n",
            "nbformat==4.4.0\n",
            "networkx==2.3\n",
            "nibabel==2.3.3\n",
            "nltk==3.3\n",
            "nose==1.3.7\n",
            "notebook==5.2.2\n",
            "np-utils==0.5.10.0\n",
            "numba==0.40.1\n",
            "numexpr==2.6.9\n",
            "numpy==1.16.1\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.0.2\n",
            "okgrade==0.4.3\n",
            "olefile==0.46\n",
            "opencv-contrib-python==3.4.3.18\n",
            "opencv-python==3.4.5.20\n",
            "openpyxl==2.5.9\n",
            "osqp==0.5.0\n",
            "packaging==19.0\n",
            "palettable==3.2.0\n",
            "pandas==0.24.2\n",
            "pandas-datareader==0.7.0\n",
            "pandas-gbq==0.4.1\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.2\n",
            "parso==0.5.1\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.7.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==4.3.0\n",
            "pip-tools==3.9.0\n",
            "plac==0.9.6\n",
            "plotly==3.6.1\n",
            "plotnine==0.5.1\n",
            "pluggy==0.7.1\n",
            "portpicker==1.2.0\n",
            "prefetch-generator==1.0.1\n",
            "preshed==2.0.1\n",
            "pretty-midi==0.2.8\n",
            "prettytable==0.7.2\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.7.1\n",
            "promise==2.2.1\n",
            "prompt-toolkit==1.0.16\n",
            "protobuf==3.7.1\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.6.0\n",
            "py==1.8.0\n",
            "pyarrow==0.14.0\n",
            "pyasn1==0.4.5\n",
            "pyasn1-modules==0.2.5\n",
            "pycocotools==2.0.0\n",
            "pycparser==2.19\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "pyemd==0.5.1\n",
            "pyglet==1.4.1\n",
            "Pygments==2.1.3\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "pymongo==3.8.0\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.0\n",
            "pyparsing==2.4.0\n",
            "pyrsistent==0.15.4\n",
            "pysndfile==1.3.3\n",
            "PySocks==1.7.0\n",
            "pystan==2.19.0.0\n",
            "pytest==3.6.4\n",
            "python-apt==1.6.4\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.5.3\n",
            "python-louvain==0.13\n",
            "python-rtmidi==1.3.0\n",
            "python-slugify==3.0.2\n",
            "python-utils==2.3.0\n",
            "pytz==2018.9\n",
            "PyWavelets==1.0.3\n",
            "PyYAML==3.13\n",
            "pyzmq==17.0.0\n",
            "qtconsole==4.5.2\n",
            "requests==2.21.0\n",
            "requests-oauthlib==1.2.0\n",
            "resampy==0.2.1\n",
            "retrying==1.3.3\n",
            "rpy2==2.9.5\n",
            "rsa==4.0\n",
            "s3fs==0.3.0\n",
            "s3transfer==0.2.1\n",
            "scikit-image==0.15.0\n",
            "scikit-learn==0.21.2\n",
            "scipy==1.3.0\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.1.post2\n",
            "seaborn==0.9.0\n",
            "semantic-version==2.6.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.6.4.post2\n",
            "simplegeneric==0.8.1\n",
            "six==1.12.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==1.8.4\n",
            "snowballstemmer==1.9.0\n",
            "sortedcontainers==2.1.0\n",
            "spacy==2.1.6\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-websupport==1.1.2\n",
            "SQLAlchemy==1.3.5\n",
            "sqlparse==0.3.0\n",
            "srsly==0.0.7\n",
            "stable-baselines==2.2.1\n",
            "statsmodels==0.10.0\n",
            "sympy==1.1.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.3\n",
            "tblib==1.4.0\n",
            "tensor2tensor==1.11.0\n",
            "tensorboard==1.14.0\n",
            "tensorboardcolab==0.0.22\n",
            "tensorflow==1.14.0\n",
            "tensorflow-estimator==1.14.0\n",
            "tensorflow-hub==0.5.0\n",
            "tensorflow-metadata==0.14.0\n",
            "tensorflow-probability==0.7.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.8.2\n",
            "testpath==0.4.2\n",
            "text-unidecode==1.2\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "tfds-nightly==1.0.2.dev201907170105\n",
            "tflearn==0.3.2\n",
            "Theano==1.0.4\n",
            "thinc==7.0.8\n",
            "toolz==0.10.0\n",
            "torch==1.1.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.3.0\n",
            "tornado==4.5.3\n",
            "tqdm==4.28.1\n",
            "traitlets==4.3.2\n",
            "tweepy==3.6.0\n",
            "typing==3.7.4\n",
            "tzlocal==1.5.1\n",
            "umap-learn==0.3.9\n",
            "uritemplate==3.0.0\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.7.0\n",
            "wasabi==0.2.2\n",
            "wcwidth==0.1.7\n",
            "webencodings==0.5.1\n",
            "Werkzeug==0.15.5\n",
            "widgetsnbextension==3.5.0\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.11.2\n",
            "xarray==0.11.3\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==1.0.0\n",
            "zipp==0.5.2\n",
            "zmq==0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca4BH-Sdxqfz",
        "colab_type": "text"
      },
      "source": [
        "***WordNet내 모든 Graph 정보 추출***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT11QhhcxgbP",
        "colab_type": "code",
        "outputId": "ed97a7db-600a-49b0-87d3-4caeccc29ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stopWords = set(stopwords.words('english'))\n",
        "\n",
        "# Synset 세부정보 추출 관련 class\n",
        "class SynsetDetails:\n",
        "\n",
        "    def __init__(self, synset):\n",
        "        self.synset = synset\n",
        "        self.definitionSynsets = self.getDefinitionSynsets(\n",
        "                                            self.getFilteredTokenizedDefinition(\n",
        "                                                tokenizer.tokenize(synset.definition())))\n",
        "\n",
        "    # 불용어 처리 definition\n",
        "    def getFilteredTokenizedDefinition(self, definition):\n",
        "        filteredTokenizedDefinition = []\n",
        "        for word in definition:\n",
        "            if word not in stopWords:\n",
        "                filteredTokenizedDefinition.append(word)\n",
        "        return filteredTokenizedDefinition\n",
        "\n",
        "    # synset definition 추출\n",
        "    def getDefinitionSynsets(self, filteredTokenisedDefinition):\n",
        "        definitionSynsets = dict()\n",
        "        for word in filteredTokenisedDefinition:\n",
        "            wordsSynsets = wordnet.synsets(word)\n",
        "            if wordsSynsets != []:\n",
        "                definitionSynsets[word] = wordsSynsets\n",
        "        return definitionSynsets\n",
        "\n",
        "# Synset이 가지고 있는 모든 relation 추출..\n",
        "def getWordnetSynsetRelations():\n",
        "    allSynsets = []\n",
        "    count = 0\n",
        "    synsetIndex = dict()\n",
        "    for synset in wordnet.all_synsets():\n",
        "        currentSynsetDetails = SynsetDetails(synset)\n",
        "        allSynsets.append(currentSynsetDetails)\n",
        "        synsetIndex[(synset.pos(),synset.offset())] = count\n",
        "        count+=1\n",
        "    return [allSynsets, synsetIndex]\n",
        "\n",
        "# matrix 형태로 graph 생성.\n",
        "def generateAndSaveWordnetGraph():\n",
        "    wordnetSynsetRelations = getWordnetSynsetRelations()\n",
        "    wordnetSynsetIndexes = wordnetSynsetRelations[1]\n",
        "    row = []\n",
        "    col = []\n",
        "    data = []\n",
        "    for synsetEntry in wordnetSynsetRelations[0]:\n",
        "        # definition에 따라서 관련 syset들 link\n",
        "        synsetLinks = list(synsetEntry.definitionSynsets.values())\n",
        "        # 상위어 \n",
        "        # 하위어 \n",
        "        # 전체어 = 단어 tree가 구성하는 전체어 : forest, organism.\n",
        "        synsetLinks.append(synsetEntry.synset.hypernyms())\n",
        "        synsetLinks.append(synsetEntry.synset.hyponyms())\n",
        "        synsetLinks.append(synsetEntry.synset.member_holonyms())\n",
        "\n",
        "        # synset link 결합.\n",
        "        synsetLinksUnion = []\n",
        "        for listOfSynsets in synsetLinks:\n",
        "            synsetLinksUnion = synsetLinksUnion + listOfSynsets\n",
        "\n",
        "        # 중복 제거. 중복된 링크 제거\n",
        "        synsetLinksUnion = set(synsetLinksUnion)\n",
        "        for linkedToSynset in synsetLinksUnion:\n",
        "            col.append(wordnetSynsetIndexes.get((synsetEntry.synset.pos(),synsetEntry.synset.offset())))\n",
        "            row.append(wordnetSynsetIndexes.get((linkedToSynset.pos(),linkedToSynset.offset())))\n",
        "            data.append(1)\n",
        "    row = np.array(row)\n",
        "    col = np.array(col)\n",
        "    data = np.array(data)\n",
        "    np.savez(\"initialGraphData\",row=row,col=col,data=data,synsetIndexes=wordnetSynsetIndexes)\n",
        "    return None\n",
        "generateAndSaveWordnetGraph()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwDkmwbAyHcc",
        "colab_type": "text"
      },
      "source": [
        "***KGB + PPR Algorithm***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UuqGHZi2oE7",
        "colab_type": "code",
        "outputId": "d496db82-e1dd-4abc-db7a-181698593345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.sparse import csc_matrix\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# 그래프 정보 불러오기\n",
        "def makeWordnetGraphAndLoadSynsetIndexDict():\n",
        "    graphDataFile = np.load(\"./initialGraphData.npz\",allow_pickle=True)\n",
        "    synsetIndexes = graphDataFile['synsetIndexes'].item()\n",
        "    length = len(synsetIndexes.keys())\n",
        "    data = graphDataFile['data']\n",
        "    row = graphDataFile['row']\n",
        "    col = graphDataFile['col']\n",
        "    wordnetAdjacencyMatrixGraph = csc_matrix((data, (row, col)),\n",
        "                                            shape=(length, length))\n",
        "    return (wordnetAdjacencyMatrixGraph, synsetIndexes)\n",
        "\n",
        "# 초기값 설정\n",
        "def getInitialRankDistribution(textSynsets, noOfNodesInGraph, synsetIndexes):\n",
        "    if(len(textSynsets)!= 0):\n",
        "        initialRankDistribution = np.zeros(noOfNodesInGraph)\n",
        "        rankSplitBetweenWords = 1/len(textSynsets)\n",
        "        rankPerSynset = 0\n",
        "        for synsetList in textSynsets:\n",
        "            rankPerSynset = rankSplitBetweenWords / (len(synsetList))\n",
        "            for synset in synsetList:\n",
        "                pos = synset.pos()\n",
        "                offset = synset.offset()\n",
        "                nodeIndex = synsetIndexes.get((pos,offset))\n",
        "                initialRankDistribution[nodeIndex] += rankPerSynset\n",
        "    else:\n",
        "        initialRankDistribution = np.full(noOfNodesInGraph, 1/noOfNodesInGraph)\n",
        "    return initialRankDistribution\n",
        "\n",
        "# 전체 그래프에 대한 Page Rank 계산\n",
        "# 문장에 등장한 단어에 대해서 Personalized 진행\n",
        "def performPPRAndGetSynsetsFromSynsets(textSynsets,transitionMatrix,\n",
        "                                        synsetIndexes,dampingFactor,iterations):\n",
        "    initialRankDistribution = getInitialRankDistribution(textSynsets,\n",
        "                                transitionMatrix.get_shape()[0],synsetIndexes)\n",
        "    pageRankVector = initialRankDistribution.copy()\n",
        "    for i in range(iterations):\n",
        "        pageRankVector = (dampingFactor\n",
        "                          * (transitionMatrix.dot(pageRankVector)))\\\n",
        "                          + (1-dampingFactor) * initialRankDistribution\n",
        "\n",
        "    return getTextSynsets(textSynsets,pageRankVector,synsetIndexes)\n",
        "\n",
        "# 가장 높은 랭킹의 의미 선택.\n",
        "def getTextSynsets(textSynsets ,pageRankVector, synsetIndexes):\n",
        "    disambiguatedSynsets = []\n",
        "    for wordSynsets in textSynsets:\n",
        "        currentSynset = None\n",
        "        currentSynsetRank = 0\n",
        "        for synset in wordSynsets:\n",
        "            pos = synset.pos()\n",
        "            offset = synset.offset()\n",
        "            synsetPagerankValue = pageRankVector[\n",
        "                                                synsetIndexes.get((pos,offset))]\n",
        "            if synsetPagerankValue > currentSynsetRank:\n",
        "                currentSynset = synset\n",
        "                currentSynsetRank = synsetPagerankValue\n",
        "        disambiguatedSynsets.append(currentSynset)\n",
        "    return disambiguatedSynsets\n",
        "\n",
        "\n",
        "def makeTransitionMatrix(adjacencyMatrix):\n",
        "    wordnetTransitionMatrix = csc_matrix.copy(adjacencyMatrix)\n",
        "    wordnetTransitionMatrix = normalize(wordnetTransitionMatrix,\n",
        "                                        norm='l1', axis=1)\n",
        "    return wordnetTransitionMatrix\n",
        "\n",
        "# 입력 문장의 단어들의 synset 반환.\n",
        "def getSetSynsets(text):\n",
        "    tokenizedText = text\n",
        "    stopWords = set(stopwords.words('english'))\n",
        "    stopWords.add(\"I\")\n",
        "    wordsWithSynsets = list()\n",
        "    sentence = list()\n",
        "    for word in tokenizedText:\n",
        "        synsets = wordnet.synsets(word)\n",
        "        if synsets != []:\n",
        "            wordsWithSynsets.append(synsets)\n",
        "            sentence.append(True)\n",
        "        else:\n",
        "            sentence.append(False)\n",
        "    return (sentence,wordsWithSynsets)\n",
        "\n",
        "\n",
        "data = makeWordnetGraphAndLoadSynsetIndexDict()\n",
        "adjacencyMatrix = data[0]\n",
        "synsetIndexes = data[1]\n",
        "transitionMatrix = makeTransitionMatrix(adjacencyMatrix)\n",
        "\n",
        "\n",
        "sentence = [\"they\", \"eat\", \"a\", \"meal\"]\n",
        "\n",
        "sentencesSynsets = list()\n",
        "sentencesMeaningfulSynsets = list()\n",
        "setOfSynsets = getSetSynsets(sentence)\n",
        "sentencesSynsets.append(setOfSynsets[0])\n",
        "sentencesMeaningfulSynsets.append(setOfSynsets[1])\n",
        "\n",
        "\n",
        "## 페이지링크 돌려서 중의성 선택됨\n",
        "disambiguatedSentence = performPPRAndGetSynsetsFromSynsets(sentencesMeaningfulSynsets[0],\n",
        "                                                           transitionMatrix,\n",
        "                                                           synsetIndexes,\n",
        "                                                           0.6,\n",
        "                                                           50)\n",
        "print(disambiguatedSentence)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[Synset('eat.v.02'), Synset('vitamin_a.n.01'), Synset('meal.n.01')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVeRxG97NjkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## in_a 오류\n",
        "## wsd 기반 사용할떄 이거 갖다 써라"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}